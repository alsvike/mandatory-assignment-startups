{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgmWEDUPo3gPQgWoGJ/LZk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpandersen61/Machine-Learning/blob/main/50StartUps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Assignment: Startups"
      ],
      "metadata": {
        "id": "gG3LBbMS4j3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Domain description"
      ],
      "metadata": {
        "id": "LUwPMv5ft4M0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "JPM-Finance is an advisory financial company with a small network of rich clients who like to invest in newly started companies (so called startups), before the profit is public.\n",
        "\n",
        "For each company there are data given by the following features:\n",
        "*   State\n",
        "*   R&D Spend\n",
        "*   Marketing Spend\n",
        "*   Administration\n",
        "*   Profit which is the label\n",
        "\n",
        "Your job is to understand, explore and prepare the data, do a linear regression analysis to be used by JPM-Finance evaluating new startups profit based on the features. The estimate of profit together with a risk analysis of the business segment, will be the foundation for financial advices to clients.\n",
        "\n",
        "A preliminary interview with the smart boss (nick name JP) and his younger energetic coordinator, Mike, has revealed that:\n",
        "\n",
        "\n",
        "1.   A few companies have some data set to 0.0, this is for the moment acceptable, meaning you\n",
        "don’t need to change these numbers into mean values or drop the respective companies.\n",
        "Some small startups actually don’t have any administration costs!\n",
        "2.   The 'State' feature is a text attribute, and from previous study not very important, meaning one can drop this feature. Thus, all calculations using `OneHotEncoder` are superfluous. Just skip them for a start. Later if You like, You can play with the `OneHotEncoder`.\n",
        "3.  If the correlation matrix of the features only has values higher than 0.20 (lower than -0.20), it is a pretty bad idea to try to combine attributes, as this can blur the picture and make\n",
        "wrong weights to the features\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LgSrnb4Ktvye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References"
      ],
      "metadata": {
        "id": "-qQf8dmB53XP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It should not be necessary to find stuff by \"Googling\" or \"ChatGPT'ing\" for the purpose of finishing this assigment. Maybe for checking only.  \n",
        "\n",
        "Try to concentrate on the following references:\n",
        "*   Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, Aurélien Géron,\n",
        " 3rd edition, Ch. 1 & 2.\n",
        "*   Coding stuff for ch. 1: https://github.com/ageron/handson-ml3/blob/main/01_the_machine_learning_landscape.ipynb\n",
        "*   Coding stuff for ch. 2: https://github.com/ageron/handson-ml3/blob/main/02_end_to_end_machine_learning_project.ipynb\n",
        "*   Stuff from Moodle room. Especially, \"End-to-End Project Model\" sections.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rz6W9bRa5vEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Python Environment"
      ],
      "metadata": {
        "id": "ZZ6LR9TOAb5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing stuff"
      ],
      "metadata": {
        "id": "4-FkaLQT8hPv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_N2k89r72nO"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhRlx8HP72nP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Akme0I72nQ"
      },
      "source": [
        "It also requires Scikit-Learn ≥ 1.0.1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhaI2FG-72nQ"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import common libraries used with learning in Python"
      ],
      "metadata": {
        "id": "HTKlhojfFFC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "eVpeh5oMPkxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "gYKJF0e1w2v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Look at the big picture and frame the problem"
      ],
      "metadata": {
        "id": "v-9a7LhTabe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions & Tasks**\n",
        "1. Define the objective in business terms. Action: Analyze what business purpose your solution is going to serve.\n",
        "To be documented – e.g. in your notebook.\n",
        "2. How shall your solution be used?\n",
        "Action: That defining one or more user stories for the solution.\n",
        "To be documented – e.g. in your notebook.\n",
        "3. What are the current solutions/workarounds (if any)?\n",
        "Action: This is N/A here as nothing is known. Otherwise useful for establishing a baseline\n",
        "to measure the performance of the intended system against.\n",
        "Nothing to be documented.\n",
        "4. How should you frame this problem (supervised/unsupervised, online/offline, etc.)?\n",
        "Action: You may re-address chapter 1 for these concepts.\n",
        "To be documented – e.g. in your notebook.\n",
        "5. How should performance be measured?\n",
        "Action: First of all select at measure that goes with the way you framed the problem –\n",
        "RMSE, Confusion matrix or something else.\n",
        "To be documented – e.g. in your notebook.\n",
        "6. Is the performance measure aligned with the business objective?\n",
        "Action: Discuss whether your performance measure makes sense regarding your business\n",
        "objective.\n",
        "To be documented – e.g. in your notebook.\n",
        "7. What would be the minimum performance needed to reach the business objective?\n",
        "Action: N/A as we have got no baseline regarding the current performance.\n",
        "Nothing to be documented.\n",
        "8. What are comparable problems? Can you reuse experience?\n",
        "Action: Reuse all the stuff and tools you know – especially, what you learned from chapter 2\n",
        "9. Is human expertise available?\n",
        "Action: N/A as we have no domain experts available. Otherwise recommendable.\n",
        "Nothing to be documented.\n",
        "10. How would you solve the problem manually?\n",
        "Action: N/A as we have got no idea about it?\n",
        "Nothing to be documented.\n",
        "11. List the assumptions you (or others have made so far)\n",
        "Action: Figure out what assumptions you actually made.\n",
        "To be documented – e.g. in your notebook.\n",
        "Note: Some assumptions have already been made in the case description. Which?\n",
        "12. Verify assumptions if possible\n",
        "Action: N/A because you have got no time for this. Otherwise, you should indeed do this.\n",
        "Nothing to be documented.\n"
      ],
      "metadata": {
        "id": "yYsH_QZcPDYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Get the data"
      ],
      "metadata": {
        "id": "LYEDWFK2vXq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is the 50_Startups.csv file, which is available in GitHub: https://raw.githubusercontent.com/jpandersen61/Machine-Learning/refs/heads/main/50_Startups.csv\n",
        "\n",
        "**Questions & Tasks:**\n",
        "1. List the data you need and how much you need.\n",
        "Action: N/A in this task. Otherwise, it is such a good idea to your need for data before going\n",
        "further. Nothing to be documented.\n",
        "2. Find and document where you can get that data.\n",
        "Action: N/A in this task because the data set is given. Nothing to be documented.\n",
        "3. Check out how much space it requires.\n",
        "Action: Probably none as the dataset is super small\n",
        "4. Check legal obligations, and get authorization if necessary.\n",
        "Action: N/A here because no legal matters are involved. Otherwise, GDPR issues,\n",
        "ownerships rights etc. should be considered. Nothing to be documented.\n",
        "5. Get access authorizations.\n",
        "Action: Nothing to e done here. Otherwise, this may be a tedious and bureaucratic procedure that has to be considered in the planning.\n",
        "6. Create a workspace (with enough storage space).\n",
        "Action: That is establishing a notebook at your PC (e.g. Jupyter) or in the cloud (e.g. Colab) for the program and data set.\n",
        "7. Get the data.\n",
        "Action: Establish a data fetch routine in your notebook. Code is to be established in your notebook, if not already done.\n",
        "8. Convert the data to a format you can easily manipulate (without changing the data itself).\n",
        "Action: Common conversions between datatypes needed as you go.\n",
        "Code is to be established in your notebook. Goes along with your coding.\n",
        "9. Ensure sensitive information is deleted or protected (e.g., anonymized).\n",
        "Action: N/A as there is none. Otherwise, legal obligations should always be checked as aminimum. Note: Data may also be considered sensitive for other reasons. Nothing to be documented.\n",
        "10. Check the size and type of data (time series, sample, geographical, etc.).\n",
        "Action: Code is to be established in your notebook like section ‘Take a Quick Look at the Data Structure’ in notebook for chapter 2.\n",
        "11. Create a test set, put it aside, and never look at it (no data snooping!).\n",
        "A problem here is that the data set is small -> Use stratification.\n",
        "Action: Make stratified test and learning sets (1 fold).\n",
        "Code is to be established in your notebook. Find your stuff in section ‘Create a Test Set’ in notebook for chapter 2"
      ],
      "metadata": {
        "id": "Vqz2AixTR9SW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Getting the data"
      ],
      "metadata": {
        "id": "cp-wNuahG7ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the dataset\n",
        "datafile=\"https://raw.githubusercontent.com/jpandersen61/Machine-Learning/refs/heads/main/50_Startups.csv\"\n",
        "dataset = pd.read_csv(datafile)\n",
        "\n"
      ],
      "metadata": {
        "id": "BXjWXlrdPrdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3. Explore the data"
      ],
      "metadata": {
        "id": "ugLcMRj8WggJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are now ready to make a notebook (in Jupyter or Colab) for exploring the data. Remember your experience from the investigation of “Housing” in Chapter 2.\n",
        "\n",
        "**Questions & Tasks**\n",
        "1. Create a copy of the data for exploration (sampling it down to a manageable size if necessary). Action: Easy action, no sampling needed.\n",
        "2. Create a notebook to keep a record of your data exploration.\n",
        "Action: You have probably already done that. A copy and paste and changes of the chapter 2 housing notebook is not illegal.\n",
        "3. Study each attribute and its characteristics. Action: Get inspired by the notebook for chapter 2 Code is to be established. Find your stuff in section ‘Take a Quick Look at the Data Structure’ in notebook for chapter 2. Consider the following attribute characteristics:\n",
        "*   Name\n",
        "*   Type (categorical, int/float, bounded/unbounded, text, structured, etc.).\n",
        "*   % of missing values.\n",
        "*   N/A. Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
        "*   Usefulness for the task.\n",
        "*   Type of distribution (Gaussian, uniform, logarithmic, etc.). Check with the selected model if OK.\n",
        "*   Do a histogram for each attribute.\n",
        "\n",
        "4. For supervised learning tasks, identify the target attribute(s); i.e. the label(s). Action: Identify target attributes, if any.\n",
        "To be documented – e.g. in the your notebook.\n",
        "5. Discover and visualize the data by scatter plots for each numerical attribute. Action: N/A because it is not considered relevant here. Nothing to be documented\n",
        "6. Study the correlations between attributes.\n",
        "Action: Make also a scatter matrix plot together with the correlation results.\n",
        "Code is to be established in your notebook like section ‘Looking for Correlations’ in notebook for chapter 2\n",
        "7. Study how you would solve the problem manually. Action: N/A. Nothing to be documented.\n",
        "8. Experiment with attribute combinations.\n",
        "Action: Code is to be established in your notebook like in section ‘Experimenting with Attribute Combinations’ in notebook for chapter 2.\n",
        "9. Identify a new promising attribute you may want to apply, if any.\n",
        "Action: Identify those with a strong correlation to the target attribute.\n",
        "To be documented – e.g. in your notebook.\n",
        "10. Identify extra data that would be useful (go back to “Get the Data”).\n",
        "Action: N/A as were are limited to ‘50 Start-ups’ dataset\n",
        "However, you may document any suggestions for extra data features – e.g. in your notebook."
      ],
      "metadata": {
        "id": "AjRlIU1gW1yd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4. Prepare the data"
      ],
      "metadata": {
        "id": "Rpizj6Q5EIWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "*   Work on copies of the data (keep the original dataset intact).\n",
        "*   Write functions for all data transformations you apply, for five reasons:\n",
        "1.   So you can easily prepare the data the next time you get a fresh dataset\n",
        "2.   So you can apply these transformations in future projects\n",
        "3.   To clean and prepare the test set\n",
        "4.   To clean and prepare new data instances once your solution is live\n",
        "5.   To make it easy to treat your preparation choices as hyperparameters"
      ],
      "metadata": {
        "id": "IP1xBMc8XfVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions & Tasks**\n",
        "1. Data cleaning: Action: N/A because no values are and no evident outliers detected. Nothing to be documented. Otherwise consider:\n",
        "*   Fix or remove outliers (optional).\n",
        "*   Fill in missing values (e.g., with zero, not mean or median…) or drop their rows (or columns).\n",
        "\n",
        "2. Feature selection: Drop the attributes that provide no useful information for the task. Action: Code is to be established in your notebook, that is find out how to apply the drop method.\n",
        "\n",
        "3. Feature engineering, where appropriate: Action: To be skipped. Nothing to be documented. Otherwise consider:\n",
        "*  Discretize continuous features.\n",
        "*  Decompose features (e.g., categorical, date/time, etc.).\n",
        "*  Add promising transformations of features (e.g., log(x), sqrt(x), etc.).\n",
        "*  Aggregate features into promising new features.\n",
        "\n",
        "4. Handle text and categorical attributes using “import OneHotEncoder”.\n",
        "Action: Find out what to do with the ‘State’ attribute.\n",
        "Code is to be established in your notebook\n",
        "Note what is stated in the case description!\n",
        "\n",
        "5. Feature scaling: Standardize or normalize features, if necessary.\n",
        "Action: Include the StandardScaler in the pipeline and observe if it does any difference when applying the LinearRegression algorithm.\n",
        "Code is to be established in your notebook e.g. find out how to apply the make_pipeline as done in section ‘Training and Evaluating on the Training Set’ in the notebook for chapter 2"
      ],
      "metadata": {
        "id": "-ak2tlb8XnI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5. Select and train a model"
      ],
      "metadata": {
        "id": "siQJLCZpKhO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "*   If the data is huge, you may want to sample smaller training sets so you can train many\n",
        "different models in a reasonable time (be aware that this penalizes complex models such as\n",
        "large neural nets or Random Forests).\n",
        "*   Once again, try to automate these steps as much as possible\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ijejRxkoYZzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions & Tasks**\n",
        "1. Train many quick-and-dirty models from different categories (e.g., linear, naive Bayes, SVM, Random Forest, neural net, etc.) using standard default parameters\n",
        "Action: In this project only try the LinearRegression algorithm using standard parameters.\n",
        "Code is to be established in your notebook as done for linear regression in section ‘Training and Evaluating on the Training Set’ in the notebook for chapter 2.\n",
        "2. Measure and compare the performance.\n",
        "For each model, compute the mean and the root mean square of the performance measure on\n",
        "a manually selected subset (5-10 data) of the training data.\n",
        "Action: Only do for our linear regression model. Code is to be established in your notebook.\n",
        "Find your stuff in section ‘Training and Evaluating on the Training Set’ in the notebook for\n",
        "chapter 2.\n",
        "3. Analyze the most significant variables for each algorithm.\n",
        "Action: Only do it for our linear regression model.\n",
        "Code is to be established in your notebook apply a similar evaluation as done in section\n",
        "‘Analyze the Best Models and Their Errors’ in the notebook for chapter 2.\n",
        "To be documented – e.g. in your notebook.\n",
        "4. Analyze the types of errors the model makes.\n",
        " What data would a human have used to avoid these errors?\n",
        "Action: Skip this if you do not observe any errors. Consider features to that may have been\n",
        "included in order to eliminate such errors.\n",
        "To be documented – e.g. in your notebook., if relevant.\n",
        "5. Perform a quick round of feature selection and engineering.\n",
        "Action: Consider which features to skip and which new feature to be defined/combined.\n",
        "To be documented – e.g. in your notebook. Code is to be established in your notebook\n",
        "accordingly by droping those features\n",
        "6. Consider another quick-and-dirty model from different categories (e.g., naive Bayes, SVM,\n",
        "Random Forest, neural net, etc.).\n",
        "Action: Considered N/A, just go on with the LinearRegression model. Nothing to be\n",
        "documented.\n",
        "7. Perform one or two more quick iterations of the five previous steps.\n",
        "Action: Condidered N/A, just go on with the LinearRegression model. Nothing to be\n",
        "documented.\n",
        "8. Shortlist the top one to two most promising models, preferring models that make different\n",
        "types of errors.\n",
        "Action: Considered N/A, just go on with the LinearRegression model. Nothing to be documented"
      ],
      "metadata": {
        "id": "8qD-HqDAcc1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6: Fine tune and test the model"
      ],
      "metadata": {
        "id": "7DGXA1ugh7wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "*   You will want to use as much data as possible for this step, especially as you move toward the end of fine-tuning.\n",
        "*   As always, automate what you can\n"
      ],
      "metadata": {
        "id": "RU8uPObxfb1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions & Tasks**\n",
        "1. Fine-tune the hyperparameters using cross-validation: Action: Try grid search on the LinearRegression algorithm. Indentify the relevant (hyper-)\n",
        "parameters and include in the search. Code is to be established in your notebook that is doing a grid search similar to what is done in section ‘Fine-Tune Your Model’ in notebook for chapter 2. Consider the following:\n",
        "*  Treat your data transformation choices as hyperparameters, especially when you are not sure about them (e.g., if you’re not sure whether to replace missing values with zeros or with the median value, or to just drop the rows).\n",
        "*  Unless there are very few hyperparameter values to explore, prefer random search over grid search. If training is very long, you may prefer a Bayesian optimization approach (e.g., using Gaussian process priors, as described by Jasper Snoek et al.).\n",
        "\n",
        "2. Try Ensemble methods. Combining your best models will often produce better performance than running them individually.\n",
        "Action: N/A as we are just applying a single model. Nothing to be documented.\n",
        "3. Once you are confident about your final model, measure its performance on the test set to estimate the generalization error. This is important!\n",
        "Action: Present your model with the set of model parameters that gives the best\n",
        "performance. Also present the set of hyper parameters that leads to this performance.Code is to be established in your notebook. To be documented – e.g. in your notebook."
      ],
      "metadata": {
        "id": "fK6Tke07fzNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions & Tasks**\n",
        "1. If you have time, consider other models (SVM, Random Forest) and compare the\n",
        "performance.\n",
        "2. If you have time, consider “OneHotEncoder” for including the ‘State’ variable into yout\n",
        "model.\n"
      ],
      "metadata": {
        "id": "ydEkMEjEgq4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 7. Report and presentation"
      ],
      "metadata": {
        "id": "-mdlVJwokwr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions & Tasks**\n",
        "1. Document what you have done.Action: Already accomplished with the actions mentioned above. Nothing to be\n",
        "documented.\n",
        "2. Create a nice and short introduction\n",
        "Make sure you highlight the big picture first.\n",
        "Action: You may skip this, but so important if you present your model outside your Machine Learning task group.\n",
        "3. Explain why your solution achieves the business objective.\n",
        "Action: To be documented – e.g. in your notebook.\n",
        "4. Do not forget to present interesting points you noticed along the way.\n",
        "Action: To be documented – e.g. in your notebook., if any.\n",
        "*  Describe what worked and what did not.\n",
        "*  List your assumptions and your system’s limitations.\n",
        "5. Ensure your key findings are communicated through beautiful visualizations or easy-to\u0002remember statements (e.g., “the median income is the number-one predictor of housing\n",
        "prices”).\n",
        "Action: To be documented – e.g. in your notebook\n"
      ],
      "metadata": {
        "id": "W_c4jZ5whDkN"
      }
    }
  ]
}